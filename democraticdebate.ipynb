{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Democratic Polling Results based on Debate Speeches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to showcase some basic skills in text preprocessing, my thought process as I proceed through the data, and a quick use of some ensemble machine learning methods. The data was downloaded recently from Kaggle, and includes democratic debates from June to the New Hampshire debate in early. The data also has some noise where some parts of the transcripts include crowd noise, announcers, or people who prompt the debators. Some noise is removed, but we keep some of the noise to indicate a baseline of corpuses which would obtain 0% polling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first goal is to set our working directory path and upload our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debate_name</th>\n",
       "      <th>debate_section</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>speaking_time_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Candidates, welcome. Vice President Biden, the...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Oh, they didn't miss anything. It's a long rac...</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Why are Senator Sanders and Mayor Buttigieg to...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Well, you know that with regard to Senator San...</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Senator Sanders, let me give you the chance to...</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Because Donald Trump lies all the time. It doe...</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>I believe that the way we beat Trump is by hav...</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>But Senator, let me follow up there and then w...</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>That's true. And that's the disappointment and...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Before I move on to Mayor Buttigieg, let me ju...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>I'm not.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Senator Klobuchar.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Bernie and I work together all the time. But I...</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Mr. Steyer, is socialism [inaudible 00:05:33]</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>I don't think there's any question, George, th...</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Andrew Yang and Senator Warren then Mayor Butt...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>First, let me say America, it's great to be ba...</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Senator Warren, you reportedly said back in 20...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Oh, Bernie and I have been friends for a long ...</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>It's an issue we can all agree on and fight fo...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Mayor Buttigieg, early in the campaign you sai...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>I'm not interested in the labels. I'm not inte...</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Are you talking about Senator Sanders?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>Yes. Because we've got to bring as many people...</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Senator Sanders, your response.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Needless to say, I've never said that, but let...</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Mayor Buttigieg, you just heard Senator Sander...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>I think there's a better way. It's true, the A...</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>George S.</td>\n",
       "      <td>Vice President Biden, how do you unify the cou...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Hampshire Democratic Debate Transcript</td>\n",
       "      <td>Part 1</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Look, Bernie says that you have to bring peopl...</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Chuck Todd</td>\n",
       "      <td>ank you Congressman.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Tim Ryan</td>\n",
       "      <td>I will only promise you one thing. When I walk...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Chuck Todd</td>\n",
       "      <td>ank you Congressman.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Tim Ryan</td>\n",
       "      <td>Your voice will be heard. Thank you.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Rachel Maddow</td>\n",
       "      <td>Congresswoman Gabbard, you have 45 seconds for...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Tulsi Gabbard</td>\n",
       "      <td>Our nation was founded on the principles of se...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Tulsi Gabbard</td>\n",
       "      <td>As president, our White House, our White House...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Rachel Maddow</td>\n",
       "      <td>Congresswoman, thank you.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Lester Holt</td>\n",
       "      <td>Secretary Castro, you have 45 seconds sir.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Speaker 11</td>\n",
       "      <td>Me llamo Julian Castro, y estoy postulando por...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Speaker 11</td>\n",
       "      <td>If I'm elected president, I will work hard eve...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Savannah G.</td>\n",
       "      <td>enator Klobuchar, the floor is yours.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Three things to know about me. First, I listen...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Secondly, I'm someone that can win, and beat D...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>nd finally, yeah, I am not the establishment p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Savannah G.</td>\n",
       "      <td>Thank you Senator.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Jose D.B.</td>\n",
       "      <td>Senator Booker, su cuarento y cinco [foreign l...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Cory Booker</td>\n",
       "      <td>Gracias. Fifty years ago, this month, my famil...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Cory Booker</td>\n",
       "      <td>Donald Trump wants us to fight him on his turf...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Jose D.B.</td>\n",
       "      <td>Senator, thank you.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Chuck Todd</td>\n",
       "      <td>ngressman O'Rourke, 45 seconds.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Beto O'Rourke</td>\n",
       "      <td>daughter Molly turned 11 this week. I'm on the...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Beto O'Rourke</td>\n",
       "      <td>If we're going to be there for them, if we're ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Beto O'Rourke</td>\n",
       "      <td>Join us. This is our moment, and the generatio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Chuck Todd</td>\n",
       "      <td>ank you Congressman.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Rachel Maddow</td>\n",
       "      <td>Senator Warren, you have 45 seconds for the fi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Thank you. It's a great honor to be here. Neve...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>But I got my chance. It was a 50 dollar a seme...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Savannah G.</td>\n",
       "      <td>We would like to thank all of the candidates t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>Transcript from Night 1 of the 2019 June Democ...</td>\n",
       "      <td>Closing Statements</td>\n",
       "      <td>Lester Holt</td>\n",
       "      <td>We certainly hope you will join us then. But f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4810 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            debate_name      debate_section  \\\n",
       "0            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "1            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "2            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "3            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "4            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "5            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "6            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "7            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "8            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "9            New Hampshire Democratic Debate Transcript              Part 1   \n",
       "10           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "11           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "12           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "13           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "14           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "15           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "16           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "17           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "18           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "19           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "20           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "21           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "22           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "23           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "24           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "25           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "26           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "27           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "28           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "29           New Hampshire Democratic Debate Transcript              Part 1   \n",
       "...                                                 ...                 ...   \n",
       "4780  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4781  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4782  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4783  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4784  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4785  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4786  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4787  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4788  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4789  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4790  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4791  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4792  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4793  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4794  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4795  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4796  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4797  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4798  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4799  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4800  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4801  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4802  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4803  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4804  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4805  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4806  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4807  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4808  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "4809  Transcript from Night 1 of the 2019 June Democ...  Closing Statements   \n",
       "\n",
       "               speaker                                             speech  \\\n",
       "0            George S.  Candidates, welcome. Vice President Biden, the...   \n",
       "1            Joe Biden  Oh, they didn't miss anything. It's a long rac...   \n",
       "2            George S.  Why are Senator Sanders and Mayor Buttigieg to...   \n",
       "3            Joe Biden  Well, you know that with regard to Senator San...   \n",
       "4            George S.  Senator Sanders, let me give you the chance to...   \n",
       "5       Bernie Sanders  Because Donald Trump lies all the time. It doe...   \n",
       "6       Bernie Sanders  I believe that the way we beat Trump is by hav...   \n",
       "7            George S.  But Senator, let me follow up there and then w...   \n",
       "8       Bernie Sanders  That's true. And that's the disappointment and...   \n",
       "9            George S.  Before I move on to Mayor Buttigieg, let me ju...   \n",
       "10      Bernie Sanders                                           I'm not.   \n",
       "11           George S.                                 Senator Klobuchar.   \n",
       "12       Amy Klobuchar  Bernie and I work together all the time. But I...   \n",
       "13           George S.      Mr. Steyer, is socialism [inaudible 00:05:33]   \n",
       "14          Tom Steyer  I don't think there's any question, George, th...   \n",
       "15           George S.  Andrew Yang and Senator Warren then Mayor Butt...   \n",
       "16         Andrew Yang  First, let me say America, it's great to be ba...   \n",
       "17           George S.  Senator Warren, you reportedly said back in 20...   \n",
       "18    Elizabeth Warren  Oh, Bernie and I have been friends for a long ...   \n",
       "19    Elizabeth Warren  It's an issue we can all agree on and fight fo...   \n",
       "20           George S.  Mayor Buttigieg, early in the campaign you sai...   \n",
       "21      Pete Buttigieg  I'm not interested in the labels. I'm not inte...   \n",
       "22           George S.             Are you talking about Senator Sanders?   \n",
       "23      Pete Buttigieg  Yes. Because we've got to bring as many people...   \n",
       "24           George S.                    Senator Sanders, your response.   \n",
       "25      Bernie Sanders  Needless to say, I've never said that, but let...   \n",
       "26           George S.  Mayor Buttigieg, you just heard Senator Sander...   \n",
       "27      Pete Buttigieg  I think there's a better way. It's true, the A...   \n",
       "28           George S.  Vice President Biden, how do you unify the cou...   \n",
       "29           Joe Biden  Look, Bernie says that you have to bring peopl...   \n",
       "...                ...                                                ...   \n",
       "4780        Chuck Todd                               ank you Congressman.   \n",
       "4781          Tim Ryan  I will only promise you one thing. When I walk...   \n",
       "4782        Chuck Todd                               ank you Congressman.   \n",
       "4783          Tim Ryan               Your voice will be heard. Thank you.   \n",
       "4784     Rachel Maddow  Congresswoman Gabbard, you have 45 seconds for...   \n",
       "4785     Tulsi Gabbard  Our nation was founded on the principles of se...   \n",
       "4786     Tulsi Gabbard  As president, our White House, our White House...   \n",
       "4787     Rachel Maddow                          Congresswoman, thank you.   \n",
       "4788       Lester Holt         Secretary Castro, you have 45 seconds sir.   \n",
       "4789        Speaker 11  Me llamo Julian Castro, y estoy postulando por...   \n",
       "4790        Speaker 11  If I'm elected president, I will work hard eve...   \n",
       "4791       Savannah G.              enator Klobuchar, the floor is yours.   \n",
       "4792     Amy Klobuchar  Three things to know about me. First, I listen...   \n",
       "4793     Amy Klobuchar  Secondly, I'm someone that can win, and beat D...   \n",
       "4794     Amy Klobuchar  nd finally, yeah, I am not the establishment p...   \n",
       "4795       Savannah G.                                 Thank you Senator.   \n",
       "4796         Jose D.B.  Senator Booker, su cuarento y cinco [foreign l...   \n",
       "4797       Cory Booker  Gracias. Fifty years ago, this month, my famil...   \n",
       "4798       Cory Booker  Donald Trump wants us to fight him on his turf...   \n",
       "4799         Jose D.B.                                Senator, thank you.   \n",
       "4800        Chuck Todd                    ngressman O'Rourke, 45 seconds.   \n",
       "4801     Beto O'Rourke  daughter Molly turned 11 this week. I'm on the...   \n",
       "4802     Beto O'Rourke  If we're going to be there for them, if we're ...   \n",
       "4803     Beto O'Rourke  Join us. This is our moment, and the generatio...   \n",
       "4804        Chuck Todd                               ank you Congressman.   \n",
       "4805     Rachel Maddow  Senator Warren, you have 45 seconds for the fi...   \n",
       "4806  Elizabeth Warren  Thank you. It's a great honor to be here. Neve...   \n",
       "4807  Elizabeth Warren  But I got my chance. It was a 50 dollar a seme...   \n",
       "4808       Savannah G.  We would like to thank all of the candidates t...   \n",
       "4809       Lester Holt  We certainly hope you will join us then. But f...   \n",
       "\n",
       "      speaking_time_seconds  \n",
       "0                      18.0  \n",
       "1                      36.0  \n",
       "2                       4.0  \n",
       "3                      41.0  \n",
       "4                      21.0  \n",
       "5                      41.0  \n",
       "6                      39.0  \n",
       "7                      12.0  \n",
       "8                      23.0  \n",
       "9                      11.0  \n",
       "10                      1.0  \n",
       "11                      3.0  \n",
       "12                     65.0  \n",
       "13                      5.0  \n",
       "14                     61.0  \n",
       "15                      4.0  \n",
       "16                     67.0  \n",
       "17                     11.0  \n",
       "18                     57.0  \n",
       "19                     27.0  \n",
       "20                     11.0  \n",
       "21                     60.0  \n",
       "22                      0.0  \n",
       "23                     39.0  \n",
       "24                      2.0  \n",
       "25                     74.0  \n",
       "26                      7.0  \n",
       "27                     57.0  \n",
       "28                      3.0  \n",
       "29                     54.0  \n",
       "...                     ...  \n",
       "4780                    NaN  \n",
       "4781                    NaN  \n",
       "4782                    NaN  \n",
       "4783                    NaN  \n",
       "4784                    NaN  \n",
       "4785                    NaN  \n",
       "4786                    NaN  \n",
       "4787                    NaN  \n",
       "4788                    NaN  \n",
       "4789                    NaN  \n",
       "4790                    NaN  \n",
       "4791                    NaN  \n",
       "4792                    NaN  \n",
       "4793                    NaN  \n",
       "4794                    NaN  \n",
       "4795                    NaN  \n",
       "4796                    NaN  \n",
       "4797                    NaN  \n",
       "4798                    NaN  \n",
       "4799                    NaN  \n",
       "4800                    NaN  \n",
       "4801                    NaN  \n",
       "4802                    NaN  \n",
       "4803                    NaN  \n",
       "4804                    NaN  \n",
       "4805                    NaN  \n",
       "4806                    NaN  \n",
       "4807                    NaN  \n",
       "4808                    NaN  \n",
       "4809                    NaN  \n",
       "\n",
       "[4810 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir(\"path of code\")\n",
    "debates = pd.read_csv(\"debate_transcripts.csv\", encoding=\"unicode_escape\") # Download the dataset\n",
    "debates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use some basic regular expressions to remove prompters, moderators, and unnamed speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = debates['speaker'].apply(lambda x: x.lower())\n",
    "debates = debates[~speakers.str.contains(\"speaker.*|moderator.*|george s.|chuck todd\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next take a look at every unique debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New Hampshire Democratic Debate Transcript',\n",
       "       'January Iowa Democratic Debate Transcript',\n",
       "       'December Democratic Debate Transcript: Sixth Debate from Los Angeles',\n",
       "       'November Democratic Debate Transcript \\x96 5th Debate Transcript from Atlanta',\n",
       "       'October Democratic Debate Transcript: 4th Debate in Ohio',\n",
       "       'September Houston Democratic Debate Transcript \\x96 Third Debate',\n",
       "       'Transcript of July Democratic Debate 2nd Round, Night 2: Full Transcript July 31, 2019',\n",
       "       'Transcript of July Democratic Debate 2nd Round Night 1: Full Transcript July 30, 2019',\n",
       "       'Transcript from Night 2 of the First 2019 June Democratic Debates',\n",
       "       'Transcript from Night 1 of the 2019 June Democratic Debates'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debates['debate_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are 8 total debates that have been held. We look to map specific words to a specific debate title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_name = debates['debate_name'].apply(lambda x: x.lower())\n",
    "\n",
    "debate_map = {'hampshire' : 'New Hampshire Debate',\n",
    "'january': 'Iowa Debate',\n",
    "'december': 'Los Angeles Debate',\n",
    "'november' : 'Atlanta Debate',\n",
    "'october' : 'Ohio Debate',\n",
    "'september' : 'Houston Debate',\n",
    "'july' : '2nd Debate',\n",
    "'june' : '1st Debate'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look to parse through the debate_name column of our dataframe. We define a function given an input x that will cycle through our map and look for a match and return our value for a given key. That value is then returned. We apply this to our column to get a consistent format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debate_name_parser(x):\n",
    "    group = \"unknown\"\n",
    "    for key in debate_map:\n",
    "        if key in x:\n",
    "            group = debate_map[key]\n",
    "            break\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Putts\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "debates['debate_name'] = debate_name.apply(lambda x: debate_name_parser(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at the uniqie values for our speaker and debate_names columns. We look to combine all text that a single speaker said at a single event. For example, we combine all text from Joe Biden spoken at the New Hampshire Debate and set it to a single corpus. All of this text cam be later given a target value: his polling results at the New Hampshire debate. This corpus would be differentiated from the combined text of Joe Biden from the Iowa caucus, and his adjoined polling results would reflect that debate specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New Hampshire Debate', 'Iowa Debate', 'Los Angeles Debate',\n",
       "       'Atlanta Debate', 'Ohio Debate', 'Houston Debate', '2nd Debate',\n",
       "       '1st Debate'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uqdebate = debates['debate_name'].unique()\n",
    "uqdebate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Joe Biden', 'Bernie Sanders', 'Amy Klobuchar', 'Tom Steyer',\n",
       "       'Andrew Yang', 'Elizabeth Warren', 'Pete Buttigieg',\n",
       "       'Linsey Davis', 'David Muir', 'Monica Hernandez', 'Adam Sexton',\n",
       "       'Devin Dwyer', 'Rachel Scott', 'Announcer', 'Wolf Blitzer',\n",
       "       'Abby Phillips', 'B. Pfannenstiel', 'Brianne P.', 'Judy Woodruff',\n",
       "       'Amy Walter', 'Stephanie Sy', 'Tim Alberta', 'Amna Nawaz',\n",
       "       'Yamiche A.', 'Rachel Maddow', 'Andrea Mitchell', 'Kamala Harris',\n",
       "       'Cory Booker', 'Kristen Welker', 'Ashley Parker', 'Tulsi Gabbard',\n",
       "       'Anderson Cooper', 'Erin Burnett', 'Marc Lacey', 'Julian Castro',\n",
       "       \"Beto O'Rourke\", 'A. Cooper', 'Jake Tapper', 'Voiceover',\n",
       "       'Jorge Ramos', 'Sec. Castro', 'Dana Bash', 'Bill de Blasio',\n",
       "       'Michael Bennet', 'Jay Inslee', 'Kirsten Gillibrand', 'Don Lemon',\n",
       "       'Crowd', 'Kirseten Gillibrand', 'Diana', 'Steve Bullock',\n",
       "       'Marianne Williamson', 'John Delaney', 'Tim Ryan', 'John H.',\n",
       "       'Female', 'Male', 'John Hickenloop', 'J. Hickenlooper',\n",
       "       'John King', 'N. Henderson', 'Savanagh G.', 'Bennett', 'Jose D.B.',\n",
       "       'Eric Stalwell', 'Eric Swalwell', 'Lester Holt', 'Savannah G.',\n",
       "       'Steve Kornacki'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uqspeaker = debates['speaker'].unique()\n",
    "uqspeaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, they didn't miss anything. It's a long race. I took a hit in Iowa and I'll probably take a hit here. Traditionally Bernie won by 20 points last time. And usually it's the neighboring senators that do well. But no matter what, I'm still in this for the same reason, we have to restore the soul of this country, bring back the middle class and make sure we bring people together. And so it's a simple proposition. It doesn't matter whether it's this one or the next. I've always viewed the first four encounters, two primaries, and two caucuses as the starting point. And so that's how I view it. Well, you know that with regard to Senator Sanders, the President wants very much to sic a label on every candidate. We're going to not only have to win this time, we have to bring along the United States Senate. And Bernie's labeled himself, not me, a democratic socialist. I think that's the label that the President's going to lay on everyone running with Bernie if he's a nominee. And a Mayor Buttigieg is a great guy and a real patriot. He's a mayor of a small city, who has done some good things but has not demonstrated he has the ability to, and we'll soon find out, to get a broad scope of support across the spectrum, including African Americans and Latinos. Look, Bernie says that you have to bring people together and we have to have Medicare for All. But Bernie says, and he says he wrote the damn thing, but he's unwilling to sell us with the damn thing's going to cost. The fact that we're in New Hampshire, very levelheaded group of people, look at the numbers. How much is it going to cost? Who's going to pay for it? It will cost more than the entire, the entire federal budget we spend now, more than entire budget. The idea middle class taxes aren't going to go up is just crazy. When they did it in Vermont, what happened? They doubled the state income tax and then had a 14% tax on withholding. And they finally did away with it. So how much is it going to cost? When you ask Bernie that, and I'll ask him again tonight sometime, and if you ask Bernie that, he says, \\x93Go figure, I don't know, we'll find out.\\x94 I think that was on CBS. He said, \\x94 We'll find out.\\x94 Or something to that effect. Imagine you're going to unite the country walking into the Congress, \\x93I got this bill. It's going to require Medicare for everybody. I can't tell you how much it's going to cost. We'll find out later and it's likely to be double whatever \\x85 everything we spent in the federal government.\\x94 Who do you think is going to get that passed? I busted my neck getting Obamacare passed, getting every Democratic vote. I know how hard it is. 30 second- 30 second response. My proposal gives you a choice. You're going to be covered. You have Medicare if you want it, you turn [inaudible 00:16:16] we're going to restore all the cuts that they made in Obamacare. We're going to reduce drug prices, reduce prescription prices, reduce copays, et cetera. And it cost a lot of money, it costs $750 billion over 10 years. I tell you how I'm going to pay for it. I'm going to raise the capital gains rates, you pay capital gains and what your tax rate is. That'll pay for it, that's $800 billion. But here's the deal, the fact is that it's going to cost \\x85 Bernie's plan costs double, double what the taxpayers are paying for every single program we spend on in the United States of America. The politics of the past I think were not all that bad. I wrote the Violence Against Women Act. I managed the $900 billion Recovery Act, which in fact put millions and millions of dollars into his city before he came and helped save his city. I was able to do it, I was able to pass the chemical weapons ban, arms control. And I was the first major leader holding public office to call for same sex marriage. So I don't know what about the past of Barack Obama and Joe Biden was so bad. What happened? What is it that he wants to do away with? We were just beginning. \\x85 Happened, what is it that he wants to do away with? We were just beginning. It was just the beginning of what will be the future of moving this country beyond where it is now in significant ways, and there's ways to do that, and one of the ways to do that is to make sure you have someone who knows how to get things done, and can lead the free world at the same time. I thank my colleague for saying that. It is a diversion, but here's the deal. Whomever the nominee is, the president's going to make up lies about. He thinks he has free reign right now. One of the things that I think is really important is we have to be authentic with the American people about what we're going to do and how we're going to do it. And by the way, Colonel Vindman got thrown out of the White House, walked out. I think at the same time, he should have been pinning a medal on Vindman, and not on rush Limbaugh. And I think we should all stand and give Colonel Vindman a show of how much we supported him. Stand up and clap for Vindman. Get up there. Who we are. That's who we are. We are not what Trump is. No. And the reason I wouldn't have ordered the strike, there is no evidence yet of imminent threat that was going to come from him. Look what happened, his America First policies made America alone. You cannot think of a time, David, and as long as you've been alive when NATO has said to the United States of America and to Iran, made a moral equivalence and said, both of you stand down. We are alone now, alone in that region of the world, without friends, without support, without allies. And secondly, you saw what happened when that air raid, when those missiles were fired from Iran into Iraq at Al-Assad Airbase, 64 of our heroes were wounded. I don't know what I would've done if my son were still there. I would have been so damn angry. I don't know what I would've done. But here's what happened, they had received traumatic brain injury. What did the president say? He said, \\x93headaches,\\x94 \\x93not bad,\\x94 \\x93Headaches, that's all they are.\\x94 This guy doesn't deserve to be commander- in-chief for one more day. I'm not sure what she, if she wants to pull all troops out of the Middle East, but if she does want to put all troops out of the Middle East, we saw what happens when that happened. I helped put together a 61 nation group to take out ISIS by putting fewer than 5,000 forces along the Turkish border to see to it that they, and they lost 10,000, the Kurds, lost 10,000 lives. They defeated ISIS. They ended the caliphate and then the president on a whim dealing with a man I know very well, they've now, the guy running Turkey who is more of an autocrat now than a Democrat, and what happened? We pulled out and you saw what happened. You saw the end of the effort to be able to continue to contain, contain ISIS, number one. Number two, close your eye, everybody. Remember what you saw on television. You saw a woman standing up there holding up her baby, Kurd, saying, \\x93Please don't leave us.\\x94 And our military women and men standing at, going out in their [inaudible 00:53:49] Humvees with their heads down ashamed of what they did. It didn't take a lot of men or men and women to do what needed to be done. And with regard Afghanistan, now I can say it because it was made public, I was totally against the whole notion of no nation building in Afghanistan. The only thing we should be doing is dealing with terrorism in that region. I've been in every part of Afghanistan, not in combat like my friend has, but in helicopter and/or on a vehicle in every part of it as senator and vice president. Here's what I saw, there is no possibility of uniting that country, no possibility at all of making it a whole country. But it is possible to see to it that they're not able to launch more attacks from the region on the United States of America. That's a small footprint that we needed and I argued for that in the beginning. I made a mistake and I said it 14 years ago. I trusted George Bush to keep his word. He said he was not going to go into Iraq. He said he was only using this to unite the United Nations to insist we get inspectors in to see what Saddam was doing. When we got elected, the president turned to me with the entire security apparatus and said, \\x93Joe, I want you to organize getting 156,000 troops out of Iraq.\\x94 I did that. I did that. The other thing I want to point out too is that NATO is in fact going to crumble if we don't beat Trump. NATO is in real trouble. We need NATO for more reasons than just physical security. We need NATO to make sure that we do not allow Russia to continue to have its influence in Eastern Europe in ways that it had before. It wasn't just to stop the Soviet Union from coming into the United States, coming into Europe. It was to make sure that we did not have a kleptocracy taking over that part of the world, to unite Europe in our behalf. I know how to deal with them. I know every one of these world leaders by their first names. They call me. I talked to them and I believe I can get it done. That's not what I said, I was part of the reason putting that deal together with Iran. I was there. I was involved in that. I was also part of the deal putting together the Paris Climate Accord. I brought in the Chinese. I was part of that. I've been part of every major initiative we've had relative to diplomacy. I have not argued for the placement of major numbers of US combat troops. I have said, along with the President of the United States, Barack Obama as his partner, I have said, we have to strengthen NATO to make it clear that we keep our commitments when we make them. Like we don't keep our commitments to the Kurds. We must keep our commitments when we make them. Otherwise, we have no power whatsoever. And it's not about making sure we're policeman of the world. The only way not to become the policeman of the world is to have allies who will join us in dealing with failed States and terrorism. And it has to be done jointly by a whole lot of people and it doesn't require large number of US troops, and I've never said that. Here's the deal. The biggest mistake that Bernie made, that Senator Sanders made, he voted to give the gun manufacturers, the only major industry in America, a loophole that does not allow them to be sued for the carnage they are creating. First thing I'll do as President is work to get rid of that. It's going to be hard. Think of all the thousands and thousands of people who died. And I might add Bernie, while you were representing your constituency, an awful lot of people [inaudible 00:13:18] your gun state and they've come around. In fact, all those folks in California, New York, Pennsylvania, they're getting killed by the thousands during the same period. I come from a state that's a major gun owning stare. I introduced the first assault weapons ban. I in fact got it passed. I'm the only guy that beat the NRA twice. While I was pushing the Brady Background Bill to check background checks, Bernie voted five times against that when he was in the House. So look, the other thing is that we have to be held accountable for the things we did, I'm the guy that set up drug courts. I set them up. I wrote it into law and it never got funded. And also on opioids, I'm the guy who's already begun to make a down payment. In the Cures Act I put in $1 billion to fight opioid addiction. And lastly, my time is going to be up, surely. Here's the deal. Those Chief Executive Officer of drug companies, they should not only be fined, they should go to jail. We ought to be able to sue the gun industry. If you say the rest of what I said. I said that we're going to not appoint anyone who did not have a view that unenumerated rights existed in the Constitution. That's not a specific test. It's a generic test. And only way, the only reason women have the right to choose is because it's determined that there's unenumerated rights coming from the Ninth Amendment in the Constitution. That's what I said. And I was part of the reason why Elena Kagan, who worked for me, we got onto the Supreme Court. I was part of the reason why Ruth Bader Ginsburg is on the Court. I was part of the reason why Sotomayer is on the Court and she will swear me in. I presided, and I'm the reason why this right wasn't taken away a long time ago because I almost single handedly made sure that Robert Bork did not get on the Court because he did not think there should be enumerated rights [inaudible 00:18:04]. Let's get that straight. Yes. Look, here's the deal. Litmus test on abortion relates to the fundamental value of the Constitution. A woman does have a right to choose. I would in fact, if they rule it to be unconstitutional, I will send to the United States Congress and it will pass, I believe, a bill that\\x85 Excuse me, legislates Roe V. Wade adjusted by Casey. It's a woman's right to do that. Period. And if you call that a litmus test it's a litmus test, but what I was talking about in the past, so no one gets confused here, is if there is no\\x85 If you read the Constitution very, very narrowly and say there are no unenumerated rights. If the doesn't say it in the Constitution that doesn't exist, you cannot have any of the things I care about, any of the things I care about as a progressive member of the United States Congress at the time, and as Vice President and as a member of society. I agree with Ruth Bader Ginsburg. That's who I agree with. And I agree the way you deal with Citizens United is pass a constitutional amendment I introduced 25 years ago saying that only public money can be spent in elections. Period. Not private money, not billionaires, not money from special interests. Period. That's the way to amend the Constitution to deal with that. In addition to that, if in fact\\x85 Look, the Democrats stood up against the man I've revered, Franklin Delano Roosevelt, he wanted to expand the Court. But they were wise enough to understand that whoever then has the majority will have the ability to abuse it and it will lose its legitimacy and there are three equal branches of government. It says the President shell nominate, the Senate shall dispose, the Senate shall make that decision, not the president. He can nominate. That's why it's so important we must win back the United States Senate this time out. And that's why as you all look at it up here in New Hampshire and around the world, excuse me, around the country, you have to ask yourself, who is most likely to help get a Senator elected in North Carolina, Georgia? Who can win Florida, Pennsylvania, Minnesota? Who can do that? Because you got to be able to win those\\x85 Well, you can. I agree. But here's the point. You've got to be able to, you've got to be able to not just win, you've got to bring along a United States Senate or this becomes moot. I'm asking you to join me and join in the support I have from the overwhelming number of the members of that Black Caucus. I have more support in South Carolina in the Black Caucus and the black community than anybody else. Double what you have, or anybody else here. Well, that is quite right. This is not about polls. I'm not talking about polls. I've already spoken to Dick Harpootlian and he in fact is, I believe, sorry for what he said. But here's the deal, folks. We've got to stop taking the black community for granted. That's the starting place. Every one of the things we talked about here, for example, in South Carolina, Jim Clyburn, he has a program, 10-15-30. We should be investing our money in those communities that haven't gotten help for a long time and give most of that help to those communities. Make it a priority. We should make sure that we have no one going to jail for a drug offense, they go directly, mandatory prison. I mean, excuse me, mandatory treatment, not prison. And we fund it. And we fund it, and three days doesn't get it. It takes at least 60 to 90 days to make any progress. We have to pay for that. Just like instead of building new prisons, we build new rehabilitation centers. We have to make sure that we have a window at the Treasury Department that allows entrepreneurs who are black and brown and minorities to be able to get loans to be able to start businesses. You know, if you own a house, I know you do know, if you own a house in an all black neighborhood, same exact house in all white neighborhood, exact same shape, the house valued in the black neighborhood would be valued as worth less, making it difficult for you to accumulate wealth, as my friend at the end of the line here says. So here's the deal: we have to do much, much more. That's what got me involved in politics in the first place, redlining, to stop it. I got involved through the Civil Rights Movement, I became a public defender. That's why I got involved. There's so many things we have to do across the board, and in education, at-risk schools. We should triple the funding we have for at-risk schools to provide for three, four, and five years old to go to school, not daycare. Increase the salaries of teachers, encourage more blacks to get into teaching, especially black men, because studies show when there's a black man in a school, it increases prospects significantly, and so on. There's a lot we can do, I've laid it all out as how to do, go to joebiden.com, you'll see the whole deal, including criminal justice reform. I beg your pardon? Yes, I agree completely. There should be registration, automatic registration, turning 18, you get a driver's license, whatever you do, you automatically are registered, number one. Number two, with regard to what we're going to see in South Carolina, we're all going to be there pretty soon. We'll see whether or not it works. In response to the letter that the person, I'm not saying Bernie wrote the letter, but the senator who wrote the letter was very brisk and significant with other African Americans in South Carolina taking issue with her. But look, Amy is right, the senator's correct. That is that we, in fact, there is systematic racism, and that's why our Justice Department works so hard to go after those. You know, realize there are 35 states in the United States of America that have come up with a total of 78 laws to restrict voting just in the last five years to try to keep African Americans from voting, and brown as well, black and brown people from voting. And that will be an enormous priority in my administration as it was in ours. It's just wrong, simply wrong. Okay, thank you. I come from a family where our dad walked in one day and said, we've got to move. Don't have a job. We've got to move to a different city. I watched my dad and I met many people here in this state and others, who go through the same thing where the father's made that longest walk or the mother's made that longest walk. I was listed for the entire time I was in the United States Congress as the poorest man in the United States Congress. My net worth was net zero a couple of times. The fact of the matter is that I've never focused on money for me and I was a single dad for five years. It's not as hard as being a single mom and I had help from my sisters in the audience and others, but the fact is that I think we have to focus on what is at stake here. These aren't someone else's children. They're all our children. They're the kite strings that lift our national ambitions, they really are. They lift our national ambitions aloft. We have an overwhelming interest, overwhelming interest in seeing to it they do well. You know, 24 out of every 100 students in school today, from grade school to high school, are Latino. What are we going to do? Walk away from that? Many of them come from homes that are poor, very poor. That's why I invest so much time and energy in preschool. That's why if I only have $1 to spend, I spend it equipping the child before they get into school in the early day, than after and we talk about all those kids out there that are going to be graduating. A great number of them, as Mr. Yang said, aren't going on to college, although I think we should help with college. They're not going on to college. What they're going to do, they're going to be equipped to compete in the 21st century by training them for the new trades, the new opportunities, the new capabilities that are out there. We must focus on our children. Like I said, they're all our children, they're not somebody else's kids. Everyone, everyone, everyone, everyone, as my father would say, is entitled to be treated with dignity and respect and we're not doing it.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NHJoe = debates[(debates['speaker']=='Joe Biden') & (debates['debate_name']=='New Hampshire Debate')]\n",
    "\" \".join(NHJoe['speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debate_corpus_joiner(s,n):\n",
    "    SpeakerDebate=debates[(debates['speaker']==s) & (debates['debate_name']==n)]\n",
    "    SpeakerDebateCorpus=\" \".join(SpeakerDebate['speech'])\n",
    "    return pd.DataFrame(data=[n,s,SpeakerDebateCorpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdf = pd.DataFrame()\n",
    "for n in uqdebate:\n",
    "    for s in uqspeaker:\n",
    "        targetdf = pd.concat([targetdf,debate_corpus_joiner(s,n)], axis=1)\n",
    "targetdf = targetdf.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the dataframe we were looking for, where there is a {speaker, debate_name} pairing and a corpus corresponding to that pairing. Although some corpuses are empty due to how it was formed iteratively through all the unique names. For example, some of the earlier candidates in the 1st and 2nd debate do not appear in the Iowa Caucus, and therefore do not have speeches associated with that event. To remove these extra rows, we loop to only take {speaker, debate_name} pairings whose corpus length is greater than 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also have a piece of code that has been commented out. This code wrote part of the targetdf to a csv file so I could then manually input the polling result for each pairing. The polling results were either grabbed directly from the debates, or would be based off the nearest polling in the debate's state after the debate had occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdf = targetdf[targetdf[2].apply(len)>0]\n",
    "##targetdf.iloc[:,0:2].to_csv(r'C:\\\\Users\\\\Putts\\\\Documents\\\\Python Training\\\\debatespeaker.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next on our agenda is to read this file back in, and combine it back with our original dataframe. We call our completed dataframe 'dfcomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_polls=pd.read_csv('debatespeaker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetdf = targetdf.reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcomplete=df_with_polls.join(targetdf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcomplete = dfcomplete.rename(columns={2:'speech'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split and Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look to divide our X and Y, as well as our training/test. Our goal is to predict the New Hampshire results using all prior polling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dfcomplete[dfcomplete['debate_name']!='New Hampshire Debate']['speech']\n",
    "X_test = dfcomplete[dfcomplete['debate_name']=='New Hampshire Debate']['speech']\n",
    "Y_train = dfcomplete[dfcomplete['debate_name']!='New Hampshire Debate']['poll_results']\n",
    "Y_test = dfcomplete[dfcomplete['debate_name']=='New Hampshire Debate']['poll_results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look to create a function that preprocess the data, removing punctuation and stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def corpus_preprocessing(words):\n",
    "    step1 = [char for char in words if char not in string.punctuation]\n",
    "    step2 = ''.join(step1)\n",
    "    step3 = [word for word in step2.split() if word not in stopwords.words('english')]\n",
    "    return(step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we look to use a simple approach to vectorizing our text data, using both the CountVectorizer and the TfidfTransformer (Term Frequency Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = CountVectorizer(analyzer=corpus_preprocessing).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = bag_of_words.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(X_train_bow)\n",
    "X_train_tfidf = tfidf_transformer.transform(X_train_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick and Dirty AdaBoostRegressor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to quickly implement and test the effectiveness of our vectorized word data, we use a non-tuned AdaBoostRegressor model on the above data and take a look at the explained_variance_score for the training data. For reference, the closer explained variance is to 1 the better it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "                  n_estimators=300, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ab_model = AdaBoostRegressor(random_state=0, n_estimators=300)\n",
    "ab_model.fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707626421393457"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "polling_predictions = ab_model.predict(X_train_tfidf)\n",
    "explained_variance_score(Y_train, polling_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great score, but since the model is trained on this data it is expected for the explained variance to be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1 (AdaBoost on Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('bag_of_words', CountVectorizer(analyzer=corpus_preprocessing)),  \n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('regressor', AdaBoostRegressor(random_state=0, n_estimators=300)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bag_of_words',\n",
       "                 CountVectorizer(analyzer=<function corpus_preprocessing at 0x000002857D19FE18>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('regressor',\n",
       "                 AdaBoostRegressor(base_estimator=None, learning_rate=1.0,\n",
       "                                   loss='linear', n_estimators=300,\n",
       "                                   random_state=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32042210790918135"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh_predictions = pipeline.predict(X_test)\n",
    "explained_variance_score(Y_test, nh_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.6524</td>\n",
       "      <td>17.7846</td>\n",
       "      <td>2.85672</td>\n",
       "      <td>3.47719</td>\n",
       "      <td>2.29322</td>\n",
       "      <td>8.73269</td>\n",
       "      <td>3.76377</td>\n",
       "      <td>2.07174</td>\n",
       "      <td>2.09655</td>\n",
       "      <td>2.11143</td>\n",
       "      <td>1.9902</td>\n",
       "      <td>1.89687</td>\n",
       "      <td>1.90952</td>\n",
       "      <td>2.00571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.4</td>\n",
       "      <td>25.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>Linsey Davis</td>\n",
       "      <td>David Muir</td>\n",
       "      <td>Monica Hernandez</td>\n",
       "      <td>Adam Sexton</td>\n",
       "      <td>Devin Dwyer</td>\n",
       "      <td>Rachel Scott</td>\n",
       "      <td>Announcer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0               1              2           3            4   \\\n",
       "0    15.6524         17.7846        2.85672     3.47719      2.29322   \n",
       "1        8.4            25.7           19.8         3.6          2.8   \n",
       "2  Joe Biden  Bernie Sanders  Amy Klobuchar  Tom Steyer  Andrew Yang   \n",
       "\n",
       "                 5               6             7           8   \\\n",
       "0           8.73269         3.76377       2.07174     2.09655   \n",
       "1               9.2            24.4             0           0   \n",
       "2  Elizabeth Warren  Pete Buttigieg  Linsey Davis  David Muir   \n",
       "\n",
       "                 9            10           11            12         13  \n",
       "0           2.11143       1.9902      1.89687       1.90952    2.00571  \n",
       "1                 0            0            0             0          0  \n",
       "2  Monica Hernandez  Adam Sexton  Devin Dwyer  Rachel Scott  Announcer  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([nh_predictions,Y_test,dfcomplete['speaker'].iloc[0:14]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above explained variance is not very good. In particular, the model predicts the non-candidates substantially higher than they should be, and under-estimates Pete and Amy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 2 (Gradient Boosting for Interval Estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the accuracy is off for a lot of candidates, I wanted to make predictions on the upper and lower bounds of our polling predictions. We look to create three gradient boosting models to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create prediction intervals. Lowerbound, Median, and Upperbound models\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "LBpipeline = Pipeline([\n",
    "    ('bag_of_words', CountVectorizer(analyzer=corpus_preprocessing)),  \n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('regressor', GradientBoostingRegressor(loss='quantile',alpha=0.1, n_estimators=1000, random_state=0)),\n",
    "])\n",
    "Medpipeline = Pipeline([\n",
    "    ('bag_of_words', CountVectorizer(analyzer=corpus_preprocessing)),  \n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('regressor', GradientBoostingRegressor(loss='lad', n_estimators=1000, random_state=0)),\n",
    "])\n",
    "UBpipeline = Pipeline([\n",
    "    ('bag_of_words', CountVectorizer(analyzer=corpus_preprocessing)),  \n",
    "    ('tfidf', TfidfTransformer()),  \n",
    "    ('regressor', GradientBoostingRegressor(loss='quantile',alpha=0.9, n_estimators=1000, random_state=0)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bag_of_words',\n",
       "                 CountVectorizer(analyzer=<function corpus_preprocessing at 0x000002857D19FE18>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_patte...\n",
       "                                           learning_rate=0.1, loss='quantile',\n",
       "                                           max_depth=3, max_features=None,\n",
       "                                           max_leaf_nodes=None,\n",
       "                                           min_impurity_decrease=0.0,\n",
       "                                           min_impurity_split=None,\n",
       "                                           min_samples_leaf=1,\n",
       "                                           min_samples_split=2,\n",
       "                                           min_weight_fraction_leaf=0.0,\n",
       "                                           n_estimators=1000,\n",
       "                                           n_iter_no_change=None,\n",
       "                                           presort='deprecated', random_state=0,\n",
       "                                           subsample=1.0, tol=0.0001,\n",
       "                                           validation_fraction=0.1, verbose=0,\n",
       "                                           warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBpipeline.fit(X_train, Y_train)\n",
    "Medpipeline.fit(X_train, Y_train)\n",
    "UBpipeline.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBpredictions=LBpipeline.predict(X_test)\n",
    "Medpredictions=Medpipeline.predict(X_test)\n",
    "UBpredictions=UBpipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488535</td>\n",
       "      <td>0.411983</td>\n",
       "      <td>0.475511</td>\n",
       "      <td>0.787765</td>\n",
       "      <td>1.29721</td>\n",
       "      <td>0.489155</td>\n",
       "      <td>0.399317</td>\n",
       "      <td>0.413072</td>\n",
       "      <td>0.0205239</td>\n",
       "      <td>0.0681894</td>\n",
       "      <td>-1.12729e-06</td>\n",
       "      <td>0.000383388</td>\n",
       "      <td>8.37362e-05</td>\n",
       "      <td>-3.29463e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.3454</td>\n",
       "      <td>17.9387</td>\n",
       "      <td>5.28919</td>\n",
       "      <td>5.75073</td>\n",
       "      <td>2.26232</td>\n",
       "      <td>4.56206</td>\n",
       "      <td>3.48202</td>\n",
       "      <td>-0.0787657</td>\n",
       "      <td>0.0803889</td>\n",
       "      <td>-0.178447</td>\n",
       "      <td>4.72191e-05</td>\n",
       "      <td>-0.295439</td>\n",
       "      <td>0.506816</td>\n",
       "      <td>0.0218599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.9097</td>\n",
       "      <td>21.2422</td>\n",
       "      <td>11.2331</td>\n",
       "      <td>12.3585</td>\n",
       "      <td>6.99945</td>\n",
       "      <td>8.67148</td>\n",
       "      <td>6.56725</td>\n",
       "      <td>6.72459</td>\n",
       "      <td>6.81305</td>\n",
       "      <td>7.71983</td>\n",
       "      <td>7.50158</td>\n",
       "      <td>6.82588</td>\n",
       "      <td>6.85551</td>\n",
       "      <td>6.80128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.4</td>\n",
       "      <td>25.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>Linsey Davis</td>\n",
       "      <td>David Muir</td>\n",
       "      <td>Monica Hernandez</td>\n",
       "      <td>Adam Sexton</td>\n",
       "      <td>Devin Dwyer</td>\n",
       "      <td>Rachel Scott</td>\n",
       "      <td>Announcer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0               1              2           3            4   \\\n",
       "0   0.488535        0.411983       0.475511    0.787765      1.29721   \n",
       "1    16.3454         17.9387        5.28919     5.75073      2.26232   \n",
       "2    20.9097         21.2422        11.2331     12.3585      6.99945   \n",
       "3        8.4            25.7           19.8         3.6          2.8   \n",
       "4  Joe Biden  Bernie Sanders  Amy Klobuchar  Tom Steyer  Andrew Yang   \n",
       "\n",
       "                 5               6             7           8   \\\n",
       "0          0.489155        0.399317      0.413072   0.0205239   \n",
       "1           4.56206         3.48202    -0.0787657   0.0803889   \n",
       "2           8.67148         6.56725       6.72459     6.81305   \n",
       "3               9.2            24.4             0           0   \n",
       "4  Elizabeth Warren  Pete Buttigieg  Linsey Davis  David Muir   \n",
       "\n",
       "                 9            10           11            12           13  \n",
       "0         0.0681894 -1.12729e-06  0.000383388   8.37362e-05 -3.29463e-47  \n",
       "1         -0.178447  4.72191e-05    -0.295439      0.506816    0.0218599  \n",
       "2           7.71983      7.50158      6.82588       6.85551      6.80128  \n",
       "3                 0            0            0             0            0  \n",
       "4  Monica Hernandez  Adam Sexton  Devin Dwyer  Rachel Scott    Announcer  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([LBpredictions,Medpredictions,UBpredictions,Y_test,dfcomplete['speaker'].iloc[0:14]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the bounds don't really give us anything more helpful. It doesn't capture Pete or Amy's true value. One guess for why the method is over-estimating Biden and under-estimating Pete and Amy is that Biden's speech patterns have remained consistent throughout the debate and that Biden was polling at a very high number to begin the debate season. One thing to keep in mind is corpuses spoken at more recent debates should have more weight than speeches from July. To account for this we look at a results dataframe, and then look to weight the polling results of the training data according to recency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighing Based on Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>speaker</th>\n",
       "      <th>A. Cooper</th>\n",
       "      <th>Abby Phillips</th>\n",
       "      <th>Adam Sexton</th>\n",
       "      <th>Amna Nawaz</th>\n",
       "      <th>Amy Klobuchar</th>\n",
       "      <th>Amy Walter</th>\n",
       "      <th>Anderson Cooper</th>\n",
       "      <th>Andrea Mitchell</th>\n",
       "      <th>Andrew Yang</th>\n",
       "      <th>Announcer</th>\n",
       "      <th>...</th>\n",
       "      <th>Stephanie Sy</th>\n",
       "      <th>Steve Bullock</th>\n",
       "      <th>Steve Kornacki</th>\n",
       "      <th>Tim Alberta</th>\n",
       "      <th>Tim Ryan</th>\n",
       "      <th>Tom Steyer</th>\n",
       "      <th>Tulsi Gabbard</th>\n",
       "      <th>Voiceover</th>\n",
       "      <th>Wolf Blitzer</th>\n",
       "      <th>Yamiche A.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debate_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1st Debate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd Debate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atlanta Debate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Debate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa Debate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles Debate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire Debate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio Debate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "speaker               A. Cooper  Abby Phillips  Adam Sexton  Amna Nawaz  \\\n",
       "debate_name                                                               \n",
       "1st Debate                  0.0            0.0          0.0         0.0   \n",
       "2nd Debate                  0.0            0.0          0.0         0.0   \n",
       "Atlanta Debate              0.0            0.0          0.0         0.0   \n",
       "Houston Debate              0.0            0.0          0.0         0.0   \n",
       "Iowa Debate                 0.0            0.0          0.0         0.0   \n",
       "Los Angeles Debate          0.0            0.0          0.0         0.0   \n",
       "New Hampshire Debate        0.0            0.0          0.0         0.0   \n",
       "Ohio Debate                 0.0            0.0          0.0         0.0   \n",
       "\n",
       "speaker               Amy Klobuchar  Amy Walter  Anderson Cooper  \\\n",
       "debate_name                                                        \n",
       "1st Debate                      3.7         0.0              0.0   \n",
       "2nd Debate                      4.0         0.0              0.0   \n",
       "Atlanta Debate                  0.0         0.0              0.0   \n",
       "Houston Debate                  3.3         0.0              0.0   \n",
       "Iowa Debate                    12.3         0.0              0.0   \n",
       "Los Angeles Debate              1.0         0.0              0.0   \n",
       "New Hampshire Debate           19.8         0.0              0.0   \n",
       "Ohio Debate                     0.0         0.0              0.0   \n",
       "\n",
       "speaker               Andrea Mitchell  Andrew Yang  Announcer     ...      \\\n",
       "debate_name                                                       ...       \n",
       "1st Debate                        0.0          1.7        0.0     ...       \n",
       "2nd Debate                        0.0          2.0        0.0     ...       \n",
       "Atlanta Debate                    0.0          0.0        0.0     ...       \n",
       "Houston Debate                    0.0          3.0        0.0     ...       \n",
       "Iowa Debate                       0.0          0.0        0.0     ...       \n",
       "Los Angeles Debate                0.0          0.0        0.0     ...       \n",
       "New Hampshire Debate              0.0          2.8        0.0     ...       \n",
       "Ohio Debate                       0.0          3.0        0.0     ...       \n",
       "\n",
       "speaker               Stephanie Sy  Steve Bullock  Steve Kornacki  \\\n",
       "debate_name                                                         \n",
       "1st Debate                     0.0            0.0             0.0   \n",
       "2nd Debate                     0.0            1.0             0.0   \n",
       "Atlanta Debate                 0.0            0.0             0.0   \n",
       "Houston Debate                 0.0            0.0             0.0   \n",
       "Iowa Debate                    0.0            0.0             0.0   \n",
       "Los Angeles Debate             0.0            0.0             0.0   \n",
       "New Hampshire Debate           0.0            0.0             0.0   \n",
       "Ohio Debate                    0.0            0.0             0.0   \n",
       "\n",
       "speaker               Tim Alberta  Tim Ryan  Tom Steyer  Tulsi Gabbard  \\\n",
       "debate_name                                                              \n",
       "1st Debate                    0.0       1.3         0.0            1.3   \n",
       "2nd Debate                    0.0       1.3         0.0            1.3   \n",
       "Atlanta Debate                0.0       0.0         0.0            0.0   \n",
       "Houston Debate                0.0       0.0         0.0            0.0   \n",
       "Iowa Debate                   0.0       0.0         0.3            0.0   \n",
       "Los Angeles Debate            0.0       0.0         0.0            0.0   \n",
       "New Hampshire Debate          0.0       0.0         3.6            0.0   \n",
       "Ohio Debate                   0.0       0.0         0.0            1.0   \n",
       "\n",
       "speaker               Voiceover  Wolf Blitzer  Yamiche A.  \n",
       "debate_name                                                \n",
       "1st Debate                  0.0           0.0         0.0  \n",
       "2nd Debate                  0.0           0.0         0.0  \n",
       "Atlanta Debate              0.0           0.0         0.0  \n",
       "Houston Debate              0.0           0.0         0.0  \n",
       "Iowa Debate                 0.0           0.0         0.0  \n",
       "Los Angeles Debate          0.0           0.0         0.0  \n",
       "New Hampshire Debate        0.0           0.0         0.0  \n",
       "Ohio Debate                 0.0           0.0         0.0  \n",
       "\n",
       "[8 rows x 69 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = dfcomplete.iloc[:,0:3].groupby(['debate_name','speaker'])['poll_results'].sum().unstack().fillna(0)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_debate=np.linspace(0.2,1.8,8)\n",
    "weights_map = {uqdebate[i]:np.flip(weight_debate)[i] for i in range(len(uqdebate))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debate_weighter(x):\n",
    "    value = \"unknown\"\n",
    "    for key in weights_map:\n",
    "        if key == x:\n",
    "            return weights_map[key]           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poll_results</th>\n",
       "      <th>debate_name</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech</th>\n",
       "      <th>recency_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.4</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Oh, they didn't miss anything. It's a long rac...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.7</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Because Donald Trump lies all the time. It doe...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.8</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Bernie and I work together all the time. But I...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.6</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>I don't think there's any question, George, th...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.8</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>First, let me say America, it's great to be ba...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.2</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Oh, Bernie and I have been friends for a long ...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.4</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>I'm not interested in the labels. I'm not inte...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Linsey Davis</td>\n",
       "      <td>Thank you, Senator. David. I want to turn now ...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>David Muir</td>\n",
       "      <td>Lindsey, thank you. Good evening, all. I want ...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Monica Hernandez</td>\n",
       "      <td>Thank you George. It's an honor to be here in ...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Adam Sexton</td>\n",
       "      <td>Good evening candidates. New Hampshire is a ba...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Devin Dwyer</td>\n",
       "      <td>Welcome back to Manchester, New Hampshire and ...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Rachel Scott</td>\n",
       "      <td>Exactly, Devin. Steyer tonight calling out the...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>New Hampshire Debate</td>\n",
       "      <td>Announcer</td>\n",
       "      <td>The democratic debate. Here now, George Stepha...</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.8</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>I said 13 years ago, it was a mistake to give ...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26.2</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>When the Congress was debating whether or not ...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.3</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Thank you Wolf, and I've been very clear that ...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.3</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>I worked internationally around the world for ...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>I believe the principal job of the Commander i...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.2</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>Well, I bring a different perspective. There a...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>Wolf Blitzer</td>\n",
       "      <td>Vice President Biden, you talk a lot about you...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>Abby Phillips</td>\n",
       "      <td>Mayor Buttigieg, another critical issue you'd ...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>B. Pfannenstiel</td>\n",
       "      <td>Let's stay with the theme of America's role in...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Iowa Debate</td>\n",
       "      <td>Brianne P.</td>\n",
       "      <td>Thank you, Senator. Thank you, Senator Klobuch...</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Los Angeles Debate</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>You know, Judy, it was a constitutional necess...</td>\n",
       "      <td>1.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.0</td>\n",
       "      <td>Los Angeles Debate</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Well, Judy, what I would say is that we have a...</td>\n",
       "      <td>1.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Los Angeles Debate</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Let me make the case to the American people. A...</td>\n",
       "      <td>1.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Los Angeles Debate</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>I'm over here. Judy, Judy, sorry. Well, let me...</td>\n",
       "      <td>1.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Los Angeles Debate</td>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>It's clear why Americans can't agree on impeac...</td>\n",
       "      <td>1.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.0</td>\n",
       "      <td>Los Angeles Debate</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>So I see this as a constitutional moment. Last...</td>\n",
       "      <td>1.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2nd Debate</td>\n",
       "      <td>John King</td>\n",
       "      <td>Well, what stood out to me I think is the most...</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2nd Debate</td>\n",
       "      <td>N. Henderson</td>\n",
       "      <td>He did. That was, I think, one of the best exc...</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>37.7</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>What I meant by that is, look, Donald Trump th...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>26.7</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Okay. Well, you're quite right. We have a new ...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3.7</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Well, first the economy. We know that not ever...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1.7</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>That's right. I'm sorry? Oh, so it's difficult...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>16.3</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Thank you. It's good to be here. I think of it...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>Beunas noches. [foreign language 00:10:03]. Su...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Rachel Maddow</td>\n",
       "      <td>Because of this large field of candidates not ...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Kamala Harris</td>\n",
       "      <td>Well, let me tell you something. I hear that q...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Cory Booker</td>\n",
       "      <td>I don't think I disagree. I think we have a se...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Tulsi Gabbard</td>\n",
       "      <td>Well, first of all, let's recognize the situat...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Julian Castro</td>\n",
       "      <td>Thank you very much for that question, Lester....</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>10.3</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Beto O'Rourke</td>\n",
       "      <td>This economy has got to work for everyone and ...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Bill de Blasio</td>\n",
       "      <td>Well, we've been addressing income inequality ...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Michael Bennet</td>\n",
       "      <td>Gridlock will not magically disappear as long ...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Jay Inslee</td>\n",
       "      <td>Well, I'm a little bit surprised. I think plan...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Kirsten Gillibrand</td>\n",
       "      <td>In answer- I want to talk about- I disagree wi...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Marianne Williamson</td>\n",
       "      <td>Well, first of all, the government should neve...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>John Delaney</td>\n",
       "      <td>I think we need to do real things to help Amer...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Tim Ryan</td>\n",
       "      <td>Yes, I believe you can, but the first, let's s...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>John H.</td>\n",
       "      <td>Well, I think that the bottom line is if we do...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Savanagh G.</td>\n",
       "      <td>Good evening to you. You've called for big new...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Bennett</td>\n",
       "      <td>Senator Sanders, [crosstalk 00:01:56]. Was tha...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Jose D.B.</td>\n",
       "      <td>Thank you very much. Senator. Senator. Senator...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Eric Stalwell</td>\n",
       "      <td>Jose, I've got $100,000 in student loan debt m...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Eric Swalwell</td>\n",
       "      <td>We must always be a country where technology c...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Lester Holt</td>\n",
       "      <td>Let's talk about healthcare. This is going to ...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Savannah G.</td>\n",
       "      <td>We've got a good debate so far. We're going to...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1st Debate</td>\n",
       "      <td>Steve Kornacki</td>\n",
       "      <td>All right, well on Election Day 2020, Donald T...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     poll_results           debate_name              speaker  \\\n",
       "0             8.4  New Hampshire Debate            Joe Biden   \n",
       "1            25.7  New Hampshire Debate       Bernie Sanders   \n",
       "2            19.8  New Hampshire Debate        Amy Klobuchar   \n",
       "3             3.6  New Hampshire Debate           Tom Steyer   \n",
       "4             2.8  New Hampshire Debate          Andrew Yang   \n",
       "5             9.2  New Hampshire Debate     Elizabeth Warren   \n",
       "6            24.4  New Hampshire Debate       Pete Buttigieg   \n",
       "7             0.0  New Hampshire Debate         Linsey Davis   \n",
       "8             0.0  New Hampshire Debate           David Muir   \n",
       "9             0.0  New Hampshire Debate     Monica Hernandez   \n",
       "10            0.0  New Hampshire Debate          Adam Sexton   \n",
       "11            0.0  New Hampshire Debate          Devin Dwyer   \n",
       "12            0.0  New Hampshire Debate         Rachel Scott   \n",
       "13            0.0  New Hampshire Debate            Announcer   \n",
       "14           15.8           Iowa Debate            Joe Biden   \n",
       "15           26.2           Iowa Debate       Bernie Sanders   \n",
       "16           12.3           Iowa Debate        Amy Klobuchar   \n",
       "17            0.3           Iowa Debate           Tom Steyer   \n",
       "18           18.0           Iowa Debate     Elizabeth Warren   \n",
       "19           26.2           Iowa Debate       Pete Buttigieg   \n",
       "20            0.0           Iowa Debate         Wolf Blitzer   \n",
       "21            0.0           Iowa Debate        Abby Phillips   \n",
       "22            0.0           Iowa Debate      B. Pfannenstiel   \n",
       "23            0.0           Iowa Debate           Brianne P.   \n",
       "24           22.0    Los Angeles Debate            Joe Biden   \n",
       "25           17.0    Los Angeles Debate       Bernie Sanders   \n",
       "26            1.0    Los Angeles Debate        Amy Klobuchar   \n",
       "27            0.0    Los Angeles Debate           Tom Steyer   \n",
       "28            0.0    Los Angeles Debate          Andrew Yang   \n",
       "29           18.0    Los Angeles Debate     Elizabeth Warren   \n",
       "..            ...                   ...                  ...   \n",
       "114           0.0            2nd Debate            John King   \n",
       "115           0.0            2nd Debate         N. Henderson   \n",
       "116          37.7            1st Debate            Joe Biden   \n",
       "117          26.7            1st Debate       Bernie Sanders   \n",
       "118           3.7            1st Debate        Amy Klobuchar   \n",
       "119           1.7            1st Debate          Andrew Yang   \n",
       "120          16.3            1st Debate     Elizabeth Warren   \n",
       "121          13.0            1st Debate       Pete Buttigieg   \n",
       "122           0.0            1st Debate        Rachel Maddow   \n",
       "123          11.0            1st Debate        Kamala Harris   \n",
       "124           4.0            1st Debate          Cory Booker   \n",
       "125           1.3            1st Debate        Tulsi Gabbard   \n",
       "126           2.0            1st Debate        Julian Castro   \n",
       "127          10.3            1st Debate        Beto O'Rourke   \n",
       "128           1.0            1st Debate       Bill de Blasio   \n",
       "129           1.0            1st Debate       Michael Bennet   \n",
       "130           1.0            1st Debate           Jay Inslee   \n",
       "131           1.3            1st Debate   Kirsten Gillibrand   \n",
       "132           1.0            1st Debate  Marianne Williamson   \n",
       "133           1.0            1st Debate         John Delaney   \n",
       "134           1.3            1st Debate             Tim Ryan   \n",
       "135           1.3            1st Debate              John H.   \n",
       "136           0.0            1st Debate          Savanagh G.   \n",
       "137           1.0            1st Debate              Bennett   \n",
       "138           0.0            1st Debate            Jose D.B.   \n",
       "139           1.0            1st Debate        Eric Stalwell   \n",
       "140           1.0            1st Debate        Eric Swalwell   \n",
       "141           0.0            1st Debate          Lester Holt   \n",
       "142           0.0            1st Debate          Savannah G.   \n",
       "143           0.0            1st Debate       Steve Kornacki   \n",
       "\n",
       "                                                speech  recency_weights  \n",
       "0    Oh, they didn't miss anything. It's a long rac...         1.800000  \n",
       "1    Because Donald Trump lies all the time. It doe...         1.800000  \n",
       "2    Bernie and I work together all the time. But I...         1.800000  \n",
       "3    I don't think there's any question, George, th...         1.800000  \n",
       "4    First, let me say America, it's great to be ba...         1.800000  \n",
       "5    Oh, Bernie and I have been friends for a long ...         1.800000  \n",
       "6    I'm not interested in the labels. I'm not inte...         1.800000  \n",
       "7    Thank you, Senator. David. I want to turn now ...         1.800000  \n",
       "8    Lindsey, thank you. Good evening, all. I want ...         1.800000  \n",
       "9    Thank you George. It's an honor to be here in ...         1.800000  \n",
       "10   Good evening candidates. New Hampshire is a ba...         1.800000  \n",
       "11   Welcome back to Manchester, New Hampshire and ...         1.800000  \n",
       "12   Exactly, Devin. Steyer tonight calling out the...         1.800000  \n",
       "13   The democratic debate. Here now, George Stepha...         1.800000  \n",
       "14   I said 13 years ago, it was a mistake to give ...         1.571429  \n",
       "15   When the Congress was debating whether or not ...         1.571429  \n",
       "16   Thank you Wolf, and I've been very clear that ...         1.571429  \n",
       "17   I worked internationally around the world for ...         1.571429  \n",
       "18   I believe the principal job of the Commander i...         1.571429  \n",
       "19   Well, I bring a different perspective. There a...         1.571429  \n",
       "20   Vice President Biden, you talk a lot about you...         1.571429  \n",
       "21   Mayor Buttigieg, another critical issue you'd ...         1.571429  \n",
       "22   Let's stay with the theme of America's role in...         1.571429  \n",
       "23   Thank you, Senator. Thank you, Senator Klobuch...         1.571429  \n",
       "24   You know, Judy, it was a constitutional necess...         1.342857  \n",
       "25   Well, Judy, what I would say is that we have a...         1.342857  \n",
       "26   Let me make the case to the American people. A...         1.342857  \n",
       "27   I'm over here. Judy, Judy, sorry. Well, let me...         1.342857  \n",
       "28   It's clear why Americans can't agree on impeac...         1.342857  \n",
       "29   So I see this as a constitutional moment. Last...         1.342857  \n",
       "..                                                 ...              ...  \n",
       "114  Well, what stood out to me I think is the most...         0.428571  \n",
       "115  He did. That was, I think, one of the best exc...         0.428571  \n",
       "116  What I meant by that is, look, Donald Trump th...         0.200000  \n",
       "117  Okay. Well, you're quite right. We have a new ...         0.200000  \n",
       "118  Well, first the economy. We know that not ever...         0.200000  \n",
       "119  That's right. I'm sorry? Oh, so it's difficult...         0.200000  \n",
       "120  Thank you. It's good to be here. I think of it...         0.200000  \n",
       "121  Beunas noches. [foreign language 00:10:03]. Su...         0.200000  \n",
       "122  Because of this large field of candidates not ...         0.200000  \n",
       "123  Well, let me tell you something. I hear that q...         0.200000  \n",
       "124  I don't think I disagree. I think we have a se...         0.200000  \n",
       "125  Well, first of all, let's recognize the situat...         0.200000  \n",
       "126  Thank you very much for that question, Lester....         0.200000  \n",
       "127  This economy has got to work for everyone and ...         0.200000  \n",
       "128  Well, we've been addressing income inequality ...         0.200000  \n",
       "129  Gridlock will not magically disappear as long ...         0.200000  \n",
       "130  Well, I'm a little bit surprised. I think plan...         0.200000  \n",
       "131  In answer- I want to talk about- I disagree wi...         0.200000  \n",
       "132  Well, first of all, the government should neve...         0.200000  \n",
       "133  I think we need to do real things to help Amer...         0.200000  \n",
       "134  Yes, I believe you can, but the first, let's s...         0.200000  \n",
       "135  Well, I think that the bottom line is if we do...         0.200000  \n",
       "136  Good evening to you. You've called for big new...         0.200000  \n",
       "137  Senator Sanders, [crosstalk 00:01:56]. Was tha...         0.200000  \n",
       "138  Thank you very much. Senator. Senator. Senator...         0.200000  \n",
       "139  Jose, I've got $100,000 in student loan debt m...         0.200000  \n",
       "140  We must always be a country where technology c...         0.200000  \n",
       "141  Let's talk about healthcare. This is going to ...         0.200000  \n",
       "142  We've got a good debate so far. We're going to...         0.200000  \n",
       "143  All right, well on Election Day 2020, Donald T...         0.200000  \n",
       "\n",
       "[144 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcomplete['recency_weights'] = dfcomplete['debate_name'].apply(debate_weighter)\n",
    "dfcomplete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_weighted = dfcomplete['poll_results'].iloc[14:]* dfcomplete['recency_weights'].iloc[14:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.6524</td>\n",
       "      <td>17.7846</td>\n",
       "      <td>2.85672</td>\n",
       "      <td>3.47719</td>\n",
       "      <td>2.29322</td>\n",
       "      <td>8.73269</td>\n",
       "      <td>3.76377</td>\n",
       "      <td>2.07174</td>\n",
       "      <td>2.09655</td>\n",
       "      <td>2.11143</td>\n",
       "      <td>1.9902</td>\n",
       "      <td>1.89687</td>\n",
       "      <td>1.90952</td>\n",
       "      <td>2.00571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.4</td>\n",
       "      <td>25.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>Linsey Davis</td>\n",
       "      <td>David Muir</td>\n",
       "      <td>Monica Hernandez</td>\n",
       "      <td>Adam Sexton</td>\n",
       "      <td>Devin Dwyer</td>\n",
       "      <td>Rachel Scott</td>\n",
       "      <td>Announcer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0               1              2           3            4   \\\n",
       "0    15.6524         17.7846        2.85672     3.47719      2.29322   \n",
       "1        8.4            25.7           19.8         3.6          2.8   \n",
       "2  Joe Biden  Bernie Sanders  Amy Klobuchar  Tom Steyer  Andrew Yang   \n",
       "\n",
       "                 5               6             7           8   \\\n",
       "0           8.73269         3.76377       2.07174     2.09655   \n",
       "1               9.2            24.4             0           0   \n",
       "2  Elizabeth Warren  Pete Buttigieg  Linsey Davis  David Muir   \n",
       "\n",
       "                 9            10           11            12         13  \n",
       "0           2.11143       1.9902      1.89687       1.90952    2.00571  \n",
       "1                 0            0            0             0          0  \n",
       "2  Monica Hernandez  Adam Sexton  Devin Dwyer  Rachel Scott  Announcer  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Medpipeline.fit(X_train, Y_train_weighted)\n",
    "nh_predictions3=Medpipeline.predict(X_test)\n",
    "pd.DataFrame([nh_predictions,Y_test,dfcomplete['speaker'].iloc[0:14]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4847245510807202"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(Y_test,nh_predictions3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have yet another improvement on our desired metric. Finally I look to do a grid search over a set of hyper-parameters to choose the best model. This grid search is pretty computationally heavy so we look to use parallel computing with GridSearchCV's built in n_jobs parameter and then \"pickle\" the fitted model afterwords so we don't have to waste money on retraining it every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Tuning, Parallel Computing, and Saving the Fitted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"regressor__max_features\" : [None, \"sqrt\"],\n",
    "             \"regressor__max_depth\" : [None, 6, 8, 10],\n",
    "             \"regressor__max_leaf_nodes\": [None, 5, 10, 20], \n",
    "             \"regressor__min_impurity_decrease\": [0, 0.2, 0.3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(Medpipeline, param_grid=param_grid, cv=3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid.fit(X_train, Y_train_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "filename = 'debate_model_v1.pk'\n",
    "\n",
    "#with open('File Path'+filename, 'wb') as file:\n",
    "      #pickle.dump(grid, file)\n",
    "\n",
    "with open('Insert File Path'+filename ,'rb') as file:\n",
    "    debate_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.59839215e+01,  1.12476772e+01,  5.27597180e+00,  4.50754656e+00,\n",
       "        2.55450579e-01,  1.20031507e+01,  6.15283749e+00,  2.12468947e-01,\n",
       "        1.37895209e+00, -1.91958041e-01, -3.78835596e-01,  1.12836145e+00,\n",
       "        1.00827210e-01,  7.75666380e-03])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38432296759927875"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(Y_test,debate_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.9839</td>\n",
       "      <td>11.2477</td>\n",
       "      <td>5.27597</td>\n",
       "      <td>4.50755</td>\n",
       "      <td>0.255451</td>\n",
       "      <td>12.0032</td>\n",
       "      <td>6.15284</td>\n",
       "      <td>0.212469</td>\n",
       "      <td>1.37895</td>\n",
       "      <td>-0.191958</td>\n",
       "      <td>-0.378836</td>\n",
       "      <td>1.12836</td>\n",
       "      <td>0.100827</td>\n",
       "      <td>0.00775666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.4</td>\n",
       "      <td>25.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>Amy Klobuchar</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>Andrew Yang</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>Pete Buttigieg</td>\n",
       "      <td>Linsey Davis</td>\n",
       "      <td>David Muir</td>\n",
       "      <td>Monica Hernandez</td>\n",
       "      <td>Adam Sexton</td>\n",
       "      <td>Devin Dwyer</td>\n",
       "      <td>Rachel Scott</td>\n",
       "      <td>Announcer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0               1              2           3            4   \\\n",
       "0    15.9839         11.2477        5.27597     4.50755     0.255451   \n",
       "1        8.4            25.7           19.8         3.6          2.8   \n",
       "2  Joe Biden  Bernie Sanders  Amy Klobuchar  Tom Steyer  Andrew Yang   \n",
       "\n",
       "                 5               6             7           8   \\\n",
       "0           12.0032         6.15284      0.212469     1.37895   \n",
       "1               9.2            24.4             0           0   \n",
       "2  Elizabeth Warren  Pete Buttigieg  Linsey Davis  David Muir   \n",
       "\n",
       "                 9            10           11            12          13  \n",
       "0         -0.191958    -0.378836      1.12836      0.100827  0.00775666  \n",
       "1                 0            0            0             0           0  \n",
       "2  Monica Hernandez  Adam Sexton  Devin Dwyer  Rachel Scott   Announcer  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([debate_model.predict(X_test),Y_test,dfcomplete['speaker'].iloc[0:14]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final model does a great job at realizing who is not a candidate for president and predicts very low polling as a result. One humorous note is that this model predicts Andrew Yang nearly as low as the non-candidates and he withdrew from the primary right after the New Hampshire Debate. One thing to note is that technically each debate is not independant even though the model considers them as individual events. A human when voting will remember past debates and what the candidate stands for even without them putting on a strong showing in the individual debate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, maybe the words that Buttigieg spoke in the New Hampshire debate was only strong enough to net him 6.15% of the voters, but due to his past success in Iowa someone will poll based on that instead of the independent words spoken just at the new Hampshire Debate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some improvements I could make would be spending more time on the text-preprocessing to give more informative features. Other improvements could be made towards the goal of incorporating past results to their name, but at the current moment I like the idea that I could input any string of speech and it could output a polling result. One thing to note is that the values for polling results will generally not add to 100 as some people will poll as undecided, so we did not put restrictions on the model. Another route we could go down is to consider each number as a percent chance to win, aka a probability and use it in a classifier that outputs probabilities. We have a 0-1 binary classification where 1 = \"You won the poll\" and 0 = \"You lost the poll\". A lot of classifiers will output probabilities that a specific prediction is in class 1, and we could use that to predict a weaker sense of polling results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall this project was a lot of fun. I got to brush up on some of my basic programming and machine learning skills, as most of my time is dedicated to studying for my Master's Degree. This specific dataset called to me a bit, as it was a current events topic that I keep track of and I wanted to practice some text processing. I also got to implement \"pickling\" which I hadn't got to do before. Some next steps that I could take would be:\n",
    "\n",
    "1. Restart the project and take a large amount of time on finding the best method of text preprocessing for this use-case\n",
    "2. Keep the current text to vector method and spend time on the model selection process\n",
    "3. Transform my currently saved model into a usable API that takes in any string of text data"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
